import scrapy
import re
import unicodedata
{% for type in model.productType %}
{% if type.name == model_main.query.productType %}
from products.items import {{type.name}}
import products.spiders.{{type.name.lower()}}_type as custom_module
class {{type.name}}Spider(scrapy.Spider):
	name = "{{type.name.lower()}}"
	
# start page
	def start_requests(self):
		url = "https://www.imdb.com/chart/top?ref_=nv_mv_250"
		return [scrapy.Request(url, callback=self.main_page)]
			
# function that finds all records needed
	def main_page(self,response):	
		links = response.css("table.chart.full-width tbody")
		for link in links.css("tr"):
			yield scrapy.Request("https://www.imdb.com"+ link.css("td.titleColumn a::attr(href)").extract_first())
	
# main function that parses single entity		
	def parse(self,response):
		{{type.name.lower()}} = {{type.name}}()
		{% for prop in type.properties %}
		
		{{prop.name}} = response.css("{{prop.selector.value}}")
		
		if "{{type.name}}_{{prop.name}}" in dir(custom_module):
			{{type.name.lower()}}['{{prop.name}}']= getattr(custom_module, '{{type.name}}_{{prop.name}}')({{prop.name}})
		else:
			{{type.name.lower()}}['{{prop.name}}'] = {{prop.name}}.extract_first()
			
		{% endfor %}
		yield {{type.name.lower()}}
			
{% endif %}
{% endfor %}			
